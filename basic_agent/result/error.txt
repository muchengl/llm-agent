[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp35gkixwe/11.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpwq3z4sr4/12.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpx5qf3qkx/13.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp2_bpc_4x/14.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp2_dwtczr/15.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: config_files/16.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: config_files/17.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: config_files/18.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: config_files/19.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: config_files/20.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp_la0ta1n/22.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 159, in __call__
    score = 1.0 * self.ua_match(
                  ^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.ua_match) at 0x1196972e0>", line 69, in ua_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 121, in ua_match
    return llm_ua_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 196, in llm_ua_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpwpeghn3f/24.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 159, in __call__
    score = 1.0 * self.ua_match(
                  ^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.ua_match) at 0x1196972e0>", line 69, in ua_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 121, in ua_match
    return llm_ua_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 196, in llm_ua_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpq7de9ty4/27.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpumfswqk7/28.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmpmorf3k86/29.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp48b2s4wj/30.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: /var/folders/6y/jpf_39x114g1rzv3j57lrkf40000gn/T/tmp85rxsbo8/31.json
[Unhandled Error] LookupError("\n**********************************************************************\n  Resource \x1b[93mpunkt_tab\x1b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \x1b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \x1b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \x1b[93mtokenizers/punkt_tab/english/\x1b[0m\n\n  Searched in:\n    - '/Users/lhz/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'\n    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n")
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 145, in __call__
    score *= self.must_include(
             ^^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.must_include) at 0x119697060>", line 69, in must_include
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 106, in must_include
    and len(word_tokenize(clean_ref)) == 1
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/.venv/lib/python3.12/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/lhz/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/share/nltk_data'
    - '/Users/lhz/PycharmProjects/llm-agent/.venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

[Config file]: config_files/34.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
[Config file]: config_files/35.json
[Unhandled Error] ValueError('OPENAI_API_KEY environment variable must be set when using OpenAI API.')
Traceback (most recent call last):
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/run.py", line 331, in test
    score = evaluator(
            ^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.EvaluatorComb.__call__) at 0x1196979c0>", line 112, in __call__
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 350, in __call__
    cur_score = evaluator(trajectory, config_file, page, client)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 167, in __call__
    score *= self.fuzzy_match(
             ^^^^^^^^^^^^^^^^^
  File "<@beartype(evaluation_harness.evaluators.StringEvaluator.fuzzy_match) at 0x1196971a0>", line 69, in fuzzy_match
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/evaluators.py", line 116, in fuzzy_match
    return llm_fuzzy_match(pred, ref, intent)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/evaluation_harness/helper_functions.py", line 161, in llm_fuzzy_match
    response = generate_from_openai_chat_completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 55, in wrapper
    raise e
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 35, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lhz/PycharmProjects/llm-agent/basic_agent/llms/providers/openai_utils.py", line 250, in generate_from_openai_chat_completion
    raise ValueError(
ValueError: OPENAI_API_KEY environment variable must be set when using OpenAI API.
